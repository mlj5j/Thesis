\chapter{CMS Particle and Event Reconstruction}

After an event is chosen to be stored by the trigger system, the output from all of the sub-detectors is saved and recorded to disk as "RAW" data.  These data contain information about the response of each sub-detector, such as tracker hits and energy deposition in the calorimeters.  As was mentioned in Chapter 4, shown in Table \ref{table:subdetsignals} and Figure \ref{fig:cmsslicewhitecolourfrench291016}, the CMS was designed such that each type of particle resulting from the $pp$ collisions at the IP would leave a distinct signature in the sub-detectors.  This allows for the information to be reconstructed into lists of physics object candidates such as photons, electrons, muons, etc and quantities such as missing transverse momentum.  The particle flow (PF) algorithm performs this reconstruction by first building tracks and calorimeter clusters.  These two elements are the inputs to the reconstruction of the aforementioned physics object candidates using a "link" algorithm.

\section{Tracks}
A combinatorial track finder algorithm based on the Kalman filtering technique uses the hits in the silicon tracker to reconstruct tracks of charged particles \cite{Kalmantracking:1987fm}.  Each iteration of the algorithm is comprised of three steps:
\begin{itemize}
	\item Seed generation:  Find a seed consisting of two to three hits that is compatible with a track from a charged particle.
	\item Track finding: Use pattern recognition to identify any hits that are compatible with the trajectory implied by the seed generated in the first step.
	\item Track fitting: Determine the properties of the track, such as origin, trajectory, and transverse momentum by performing a global $\chi^2$ fit.
\end{itemize}

The first iteration uses stringent requirements on the seeds and the $\chi^2$ of the track fit to pick out isolated jets which have very high purity.  The hits associated with these high purity tracks are then removed to reduce the combinatorial complexity for subsequent iterations.  This allows successive iterations to identify less obvious tracks by progressively loosening criteria while the removal of previously associated hits mitigates the likelihood of fake tracks being built.  


\section{Calorimeter clusters}
Calorimeter clusters are constructed using energy deposition information from the calorimeters.  Clusters are formed by first identifying the seed cell (ECAL crystal or HCAL scintillating tile) that corresponds to the local maxima of an energy deposit that is above a given threshold.  Neighboring cells are then aggregated to grow topological clusters if their signals are above twice the standard deviation of the level of electronic noise.  

\section{Object identification}
At this point the tracks and calorimeter clusters are linked to form a PF block.  This linkage is done with an algorithm that quantifies the likelihood that a given track and cluster were results of the same particle.  As PF blocks are identified as object candidates they are removed from the collection prior to each subsequent iteration until all tracks and clusters have been assigned to a PF object candidate.  The following sections will outline how each of these PF objects is identified.
\subsection{Muons}
Muons are the easiest particle to identify, so they are the first objects reconstructed in the CMS.  PF Muons are classified in three categories depending on how their tracks are reconstructed:
\begin{itemize}
	\item Tracker muons:  Tracks reconstructed from the inner tracker having $p_T>0.5$ GeV and $|\vec{p}|>2.5$ GeV that, when propagated to the muon system, match at least one hit in the muon chambers.
	\item Stand-alone muons:  Tracks reconstructed only using hits in the muon system.
	\item Global muons:  Stand-alone muons that coincide with a track from the inner tracker.
\end{itemize}
After a muon is reconstructed it is given an identification or ID based on observables such as the $\chi^2$ of the track fit, how many hits were recorded per track, or how well the tracker and stand-alone tracks matched.  These IDs represent different working points (loose, medium, and tight) which correspond to increasing purity but decreasing efficiency as you move from loose toward tight.  
\label{section:muondefinitions}

\subsection{Electrons}
The next objects reconstructed in the CMS are electrons.  Bremsstrahlung in the tracker layers causes substantial energy loss and changes in momentum which requires the use of a dedicated tracking algorithm.  In place of the Kalman filtering technique, a Gausian-sum filter (GSF) algorithm is used.  This algorithm uses a weighted sum of Gaussian PDFs which does a better job of modeling the Bremsstrahlung effects than the Kalman filtering technique which uses a single Gaussian PDF.  

PF ECAL clusters are regrouped by identifying a seed cluster then associating and adding clusters from Bremsstrahlung photons to form superclusters.  The schematic in Figure \ref{fig:electrontracking} shows how the Bremsstrahlung photons are emitted in directions tangent to the trajectory of the electron.  Electrons bending in the magnetic field causes spreading of PF ECAL clusters to typically occur along the $\phi$-direction.  Two approaches are used to associate the superclusters to GSF tracks.  One is the ECAL-driven method, which uses superclusters with $p_T > 4$ GeV as seeds for the GSF track finding algorithm.  This works well for high-$p_T$ isolated electrons because the bend radius is less severe which decreases the spread of the PF ECAL clusters. This results in more of the Bremsstrahlung radiation being recovered and correctly assoiated with an electron candidate.  The second approach is the tracker-driven method which uses tracks with $p_T > 2$ GeV as seeds that are propagated out to the surface of the ECAL and used for clustering.  This method works best with soft electrons like those in jets because it relies on the high granularity of the tracker to disentangle overlapping energy deposits in the ECAL. \cite{Electrontracking:2715343}

\begin{figure}[h]
	\centering
	\includegraphics[width=0.5\linewidth]{Figures/electrontracking}
	\caption{The Bremsstrahlung photons continue along a straight trajectory while the electron path is bent by the magnetic field.  This results in energy deposited in the calorimeter for such electrons to be spread out along the $\phi$-direction.}
	\label{fig:electrontracking}
\end{figure}

As a final step, a boosted decision tree (BDT) is used to discriminate between real and fake electrons.  The BDT is given variables associated with track-cluster matching, shower shape, and tracking.  The output score of the BDT is used to classify electrons into loose, medium, and tight working points which exhibit to the same purity and efficiency trends as the muon working points.

\subsection{Photons} 
Unlike electrons, photons typically deposit most of their energy in the ECAL without interacting with the tracker therefore their reconstruction is seeded from ECAL superclusters that do not have any GSF tracks associated with them.  When photons interact with the tracker material they convert into electron-positron pairs which follow bent trajectories due to the magnetic field prior to entering the ECAL.  This causes a spread of the energy deposition along the $\phi$-direction.  The goal of the clustering algorithm for photon reconstruction is to include all of the energy deposits of electrons resulting from photon conversions.  As with the calorimeter clustering algorithm, the photon clustering starts by identifying a local energy maxima as a seed crystal. In the EB a cluster is made up of several parallel strips of crystals $5\times1$ in $\eta \times \phi$.  The first strip has the seed crystal at its center.  Neighboring strips in the $\phi$-direction are added if they have energy above a threshold of 10 GeV but less than that of the subsequent strip with a maximum of 17 strips in a cluster.  In the EE, the seed cluster is $5\times5$ with adjacent $5\times5$ clusters being added if they meet the minimum energy requirement.

Converted and unconverted photons can be differentiated by looking at how the energy is distributed in a supercluster.  The variable $R_9$ is used for this purpose.  It is defined as the ratio of the energy in a $3\times3$ crystal array to the energy in the entire supercluster.  As the energy deposits resulting from converted electrons is more spread out they result in a lower $R_9$ value than unconverted photons.  A photon is candidate is considered to be unconverted when $R_9>0.93$.  

An important point regarding the clustering algorithm is that it does not differentiate between showers resulting from photons and those resulting from electrons.  This allows for electron from $Z\rightarrow ee$ events to be used as high purity samples to study analysis inputs and for defining control regions using electron in place of photons.


\subsection{Jets}
When quarks or gluons are produced they hadronize to make cone-shaped, collimated collections of particles called jets.  The jet clustering algorithm aims to combine these particles in order to accurately measure the kinematics of the initial gluon or quark.  The algorithm uses the two distance parameters
\begin{eqnarray}
	d_{ij} &=& min(k_{T_i}^{2p},k_{T_j}^{2p})\frac{\Delta R_{ij}^2}{R^2} \\
	d_{iB} &=& k_{T_i}^{2p}
\end{eqnarray}
where $d_{ij}$ is the distance between objects $i$ and $j$ and $d_{iB}$ is the distance between object $i$ and the beam $B$.  The transverse momentum of the object is $k_T$.  The parameter $p$ is set as either -1, 0, or +1 to specify whether the anti-$k_T$, Cambridge/Aachen, or $k_T$ algorithm is used, respectively.  The difference between these three algorithms is which object pairs to combine first.  The Cambridge/Aachen algorithm clusters starts by clustering particles with the smallest angles between their 4-vectors.  The $k_T$ algorithm clusters soft particles first.  And the anti-$k_T$ algorithm clusters hard particles first. A comparison of these algorithms in Figure \ref{fig:jetclusteringalgorithms} shows that both the $k_T$ and Cambridge/Aachen algorithms result in irregular clustering of partons while the anti-$k_T$ algorithm results in more regular, circular jet shapes.  The value of $\Delta R_{ij}^2$ is defined as $(\eta_i-\eta_j)^2+(\phi_i-\phi_j)^2$ and $R$ is the distance parameter that defines the radius or cone size of the jet.

This analysis uses jets reconstructed from PF candidates using the anti-$k_T$ algorithm with the cone size set to $R= 0.4$, also known as AK4PFJets or just PFJets. The algorithm goes through the following steps:
\begin{enumerate}
	\item The smallest values of $d_{ij}$ and $d_{iB}$ are computed for all objects in the event.
	\item Objects $i$ and $j$ are merged into a single object if $d_{ij}<d_{iB}$.  
	\item Object $i$ is labeled as a jet and removed from the list if $d_{iB}<d_{ij}$. 
	\item This is repeated until there are no more objects.
\end{enumerate}

\begin{figure}[h]
	\centering
	\subfloat[$k_T$ jet clustering algorithm.][$k_T$ jet clustering algorithm.]{
		\includegraphics[width=0.6\textwidth]{Figures/kTalgorithm}
		\label{fig:kTalgorithm}}
	\qquad
	\subfloat[Cambridge/Aachen jet clustering algorithm][Cambridge/Aachen jet clustering algorithm]{
		\includegraphics[width=0.6\textwidth]{Figures/CamAachalgorithm}
		\label{fig:camaachalgorithm}}
	\quad
	\subfloat[Anti-$k_T$ jet clustering algorithm][Anti-$k_T$ jet clustering algorithm]{
		\includegraphics[width=0.6\textwidth]{Figures/antikTalgorithm}
		\label{fig:antiktalgorithm}}
	\caption{Comparison of the $k_T$, Cambridge/Aachen, and anti-$k_T$ jet clustering algorithms with the distance parameter set to $R$ = 1.  This is a sample parton-level event upon which each algorithm was applied.  Of the three, the anti-$k_T$ algorithm gives the most regularly shaped jets. Reprint from \cite{Cacciari:2008gp}}
	\label{fig:jetclusteringalgorithms}
\end{figure}

After clustering, a series of jet energy corrections (JEC) are sequentially applied to the jets in order to improve calibration and energy resolution. We define the jet $p_T$ response as 
\begin{equation}
	\mathcal{R} = \frac{p_{T}}{p_T^{gen}}
\end{equation}
where $p_T$ is the measured or reconstructed transverse momentum of a jet and $p_T^{gen}$ is the generator-level value.  Ideally the distribution of $\mathcal{R}$ would have $\langle \mathcal{R} \rangle = 1$, but this is not the case which is where the JEC come in.  The first stage of the correction process is a flat correction to remove pileup contributions from the measured jet energy.  A description of what pileup is and the mitigation process is available in Section \ref{section:pucorrection}.  The next correction is a detector response correction derived from simulation in bins of $\eta$ and $p_T$ which is derived by comparing the measured and generator-level $p_T$ in each bin.  Next is a residual correction for differences between data and detector simulation.  This step exploits momentum conservation in the transverse plain by using dijet, $Z\rightarrow \mu \mu$+jet, and $\gamma$+jet data events to derive correction factors.  The result can be summarized as
\begin{eqnarray}
	\vec{p}_{corr} &=& C \cdot p_T^{raw} \\
	 &=& C_{PU}(p_T^{raw},\eta)\cdot C_{sim}(p_T', \eta) \cdot C_{res}(p_T'', \eta) \cdot \vec{p}_{raw}
	 \label{equation:JEC}
\end{eqnarray}
where each of correction is applied sequentially such that $p_T'$ is the transverse momentum after application of $C_{PU}$ and $p_T''$ is after the all subsequent correction have been applied.  Once the JEC has been applied the mean of the jet response distribution should be very close to 1 and the width gives the jet energy resolution (JER).


\label{section:jetalgorithm}
\section{Missing transverse momentum}

The missing transverse momentum $\vec{p_T}$ is defined as the negative vector sum of transverse momentum over all PF objects and can be written as
\begin{equation}
	\vec{p_T}^{miss} = -\sum_{i}\vec{p_{Ti}}.
\end{equation}
We call the magnitude of this quantity the missing transverse energy $E_T^{miss}$.  For reasons described in Section \ref{section:RandS} a similar variable called the Hard $E_T^{miss}$ is used in which only objects with $p_T > 30$ GeV are used so we have 
\begin{equation}
	Hard E_T^{miss} = |-\sum_{i}\vec{p_{Ti}}\cdot \Theta(30 -p_{Ti})|
\end{equation}
where the $p_T$ is measured in units of GeV and $\Theta$ is a Heaviside function.

\label{section:MET}

\section{Pileup mitigation}

Multiple interactions occurring in each bunch crossing is referred to as pileup (PU) and can affect reconstruction performance.  The number of PU interaction, $\mu$, is simply the number of of interactions in a bunch crossing.  It's calculated using Equation \ref{equation:PUcalc} where $L_{inst}$ is the instantaneous luminosity, $\sigma_{in}^{pp}$ is the total proton-proton inelastic cross section, and $f_{rev}$ is the LHC orbit frequency.  
\begin{equation}
	\mu = L_{inst}\frac{\sigma_{in}^{pp}}{f_{rev}}
	\label{equation:PUcalc}
\end{equation}
Figures \ref{fig:pileuppp201669200}, \ref{fig:pileuppp201769200}, and \ref{fig:pileuppp201869200} show the distributions of PU interactions during each year of datataking used in this analysis.
\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\linewidth]{Figures/pileup_pp_2016_69200}
	\caption[Pileup distribution for 2016.]{Pileup distribution for 2016}
	\label{fig:pileuppp201669200}
\end{figure}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\linewidth]{Figures/pileup_pp_2017_69200}
	\caption[Pileup distribution for 2017]{Pileup distribution for 2017.}
	\label{fig:pileuppp201769200}
\end{figure}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\linewidth]{Figures/pileup_pp_2018_69200}
	\caption[Pileup distribution for 2018]{Pileup distribution for 2018.}
	\label{fig:pileuppp201869200}
\end{figure}

When analyzing an \textit{event} we are looking at a single hard-scatter vertex in a bunch crossing.  In order to do this, the PF algorithm must mitigate effects associated with additional PU vertices.  Charged particles have track information from the silicon tracker and can be removed if they are associated with one of the additional PU vertices on an object-by-object basis, but this is not the case for neutral particles such as photons and neutral hadrons.  These effects are instead removed from the event on average.  Particular care must be taken to correct isolation variables, which take sum energy deposited within a  specified cone of a target object.  For example, an isolation variable for photons would sum the energy deposited from different object types (like charged hadrons, neutral hadrons, etc) in the vicinity of a target photon.  For isolation variables the PU corrections are given by $\rho A_{eff}$ where $\rho$ is the event-specific energy density per unit area in $\eta \times \phi$ and $A_{eff}$ is an effective area specific to the type of isolation.  The corrected isolation variable would then be given by
\begin{equation}
	I_{corrected} = max(I - \rho A_{eff}, 0) 
\end{equation}
, with $I$ being the uncorrected isolation, and is referred to as the $\rho$-corrected isolation.
\label{section:pucorrection}
%For example, the effect on photon isolation is mitigated using the average $p_T$ density $\rho$, and is referred to as the $\rho$-corrected isolation.  The $p_T$ of all of the PF candidates in a fixed grid in $\phi$ and $\eta$ are summed and then divided by the are in $\eta \times \phi$.  The average contribution of PU to the isolation variable would be $\rho$ multiplied by an effective area $A_{eff}$ for photons.


%Instead of calculating $\mu$ for each individual bunch crossing it is calculated in blocks of luminosity called lumi-sections,which are about 23.3 seconds long, as an average value.  